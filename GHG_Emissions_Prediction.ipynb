{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32efb7ab",
   "metadata": {},
   "source": [
    "# Supply Chain Emissions Modeling Using Industry and Commodity Data (2010â€“2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1c6fc",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "You have annual supply chain emission data from 2010â€“2016 categorized into industries and commodities. The goal is to develop a regression model that can predict the Supply Chain Emission Factors with Margins based on descriptive and quality metrics (substance, unit, reliability, temporal/geographical/technological/data collection correlations, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae1c80",
   "metadata": {},
   "source": [
    "# ðŸŒ± Greenhouse Gas Emission Prediction Project\n",
    "\n",
    "![GHG Emissions](https://www.shalom-education.com/wp-content/uploads/2022/12/Shutterstock_1667551381-1-1024x1006.jpg)\n",
    "\n",
    "**Project Goal:**  \n",
    "To analyze and predict greenhouse gas (GHG) emissions from various U.S. industries and commodities using the official dataset from [data.gov](https://catalog.data.gov/dataset/supply-chain-greenhouse-gas-emission-factors-for-us-industries-and-commodities).\n",
    "\n",
    "![GHG Emissions](https://edg.epa.gov/EPALogo.svg)\n",
    "\n",
    "**Source:**  \n",
    "[Supply Chain Greenhouse Gas Emission Factors](https://catalog.data.gov/dataset/supply-chain-greenhouse-gas-emission-factors-for-us-industries-and-commodities)\n",
    "\n",
    "  \n",
    "**Tools:** Python, Pandas, Scikit-learn, Matplotlib, Seaborn  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc9ed5",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Dataset Overview\n",
    "\n",
    "This dataset contains supply chain emission factors associated with various U.S. industries and commodities.\n",
    "\n",
    "**Key Columns:**\n",
    "- `Code`: Industry classification code\n",
    "- `Industry_Name`: Name of the industry\n",
    "- `Commodity`: Item or commodity name\n",
    "- `GHG_Emissions_kgCO2e`: GHG emissions per unit (kg CO2 equivalent)\n",
    "- `Units`: Measurement units (e.g., [kg/2018 USD, purchaser price])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409dc066",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Data Preprocessing\n",
    "\n",
    "Steps:\n",
    "- Handle missing values\n",
    "- Convert units where needed\n",
    "- Encode categorical features\n",
    "- Normalize/scale numeric columns\n",
    "\n",
    "## ðŸ¤– Model Building & Evaluation\n",
    "\n",
    "We aim to predict `GHG_Emissions_kgCO2e` using regression models.\n",
    "\n",
    "Models to try:\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- MAE (Mean Absolute Error)\n",
    "- RÂ² Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2558455",
   "metadata": {},
   "source": [
    "##### Steps:\n",
    "- Step 1: Import Required Libraries\n",
    "- Step 2: Load Dataset\n",
    "- Step 3: Data Preprocessing (EDA+Cleaning+Encoding)\n",
    "- Step 4: Training\n",
    "- Step 5: Prediction and Evaluation\n",
    "- Step 6: Hyperparameter Tuning\n",
    "- Step 7: Comapartive Study and Slecting the Best model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118424af",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e58624",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670b39a",
   "metadata": {},
   "source": [
    "# Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7223e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx'  # Replace with actual path\n",
    "years = range(2010, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "years[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Commodity')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Industry')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464213c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        df_com = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Commodity')\n",
    "        df_ind = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Industry')\n",
    "        \n",
    "        df_com['Source'] = 'Commodity'\n",
    "        df_ind['Source'] = 'Industry'\n",
    "        df_com['Year'] = df_ind['Year'] = year\n",
    "        \n",
    "        df_com.columns = df_com.columns.str.strip()\n",
    "        df_ind.columns = df_ind.columns.str.strip()\n",
    "\n",
    "        df_com.rename(columns={\n",
    "            'Commodity Code': 'Code',\n",
    "            'Commodity Name': 'Name'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        df_ind.rename(columns={\n",
    "            'Industry Code': 'Code',\n",
    "            'Industry Name': 'Name'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        all_data.append(pd.concat([df_com, df_ind], ignore_index=True))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079554d-36f7-4163-b1af-f8fddcdc1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bcf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(all_data, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12443c98",
   "metadata": {},
   "source": [
    "# Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # Checking columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is no data avaialble in Unnamed coulmn so we will drop the column\n",
    "df.drop(columns=['Unnamed: 7'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())   # Checking data types and non-null counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6edbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T # Checking summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b30be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # Checking for null values in each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf7fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "sns.histplot(df['Supply Chain Emission Factors with Margins'], bins=50, kde=True)\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical variables\n",
    "print(df['Substance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Unit'].value_counts()) # Checking unique values in 'Unit' with count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Unit'].unique()) # Checking unique values in 'Unit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Source'].value_counts()) # Checking unique values in 'Source' with count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Substance'].unique() # Checking unique values in 'Substance' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "substance_map={'carbon dioxide':0, 'methane':1, 'nitrous oxide':2, 'other GHGs':3} # Mapping substances to integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Substance']=df['Substance'].map(substance_map) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fdb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Substance'].unique() # Checking unique values in 'Substance' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc042f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Unit'].unique()) # Checking unique values in 'Unit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f897a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_map={'kg/2018 USD, purchaser price':0, 'kg CO2e/2018 USD, purchaser price':1} # Mapping units to integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Unit']=df['Unit'].map(unit_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Unit'].unique()) # Checking unique values in 'Unit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84076edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Source'].unique()) # Checking unique values in 'Source' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_map={'Commodity':0, 'Industry':1} # Mapping sources to integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Source']=df['Source'].map(source_map)   # applying the mapping to 'Source' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Source'].unique()) # Checking unique values in 'Source' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39744e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Checking data types and non-null counts after mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a70cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Code.unique() # Checking unique values in 'Code' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name.unique() # Checking unique values in 'Name' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Name.unique()) # Checking number of unique values in 'Name' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2992b",
   "metadata": {},
   "source": [
    "##### Top 10 Emmiting Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d299cd-6903-4c2c-b073-a1ac5a304356",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_emitters = df[['Name', 'Supply Chain Emission Factors with Margins']].groupby('Name').mean().sort_values(\n",
    "    'Supply Chain Emission Factors with Margins', ascending=False).head(10) \n",
    "\n",
    "# Resetting index for better plotting\n",
    "top_emitters = top_emitters.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dd05f-6cc0-4291-bc22-afd854999e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_emitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f181c-dc8d-45ce-9b16-65a0eb655c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the top 10 emitting industries\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# Example: Top emitting industries (already grouped)\n",
    "sns.barplot(\n",
    "    x='Supply Chain Emission Factors with Margins',\n",
    "    y='Name',\n",
    "    data=top_emitters,\n",
    "    hue='Name',\n",
    "    palette='pastel'  # Use 'Blues', 'viridis', etc., for other color maps\n",
    ")\n",
    "\n",
    "# Add ranking labels (1, 2, 3...) next to bars\n",
    "for i, (value, name) in enumerate(zip(top_emitters['Supply Chain Emission Factors with Margins'], top_emitters.index), start=1):\n",
    "    plt.text(value + 0.01, i - 1, f'#{i}', va='center', fontsize=11, fontweight='bold', color='black')\n",
    "\n",
    "plt.title('Top 10 Emitting Industries', fontsize=14, fontweight='bold') # Title of the plot \n",
    "plt.xlabel('Emission Factor (kg CO2e/unit)') # X-axis label\n",
    "plt.ylabel('Industry') # Y-axis label\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6) # Adding grid lines for better readability\n",
    "plt.tight_layout() # Adjust layout to prevent overlap\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d361b2c",
   "metadata": {},
   "source": [
    "##### Drop non-numeric columns not needed,\n",
    "##### Alos drop Code and Year columns since there is no need of both of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35951b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['Name','Code','Year'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d26da",
   "metadata": {},
   "source": [
    "##### Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Supply Chain Emission Factors with Margins']) # Feature set excluding the target variable\n",
    "y = df['Supply Chain Emission Factors with Margins'] # Target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5d358-18ed-4e1c-b205-4e3a42801fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fb8e6-c355-49f2-86ca-4570666a01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf683ba",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot for Substance\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.countplot(x=df[\"Substance\"])\n",
    "plt.title(\"Count Plot: Substance\")\n",
    "plt.xticks()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot for Unit\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.countplot(x=df[\"Unit\"])\n",
    "plt.title(\"Count Plot: Unit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot for Source\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df[\"Source\"])\n",
    "plt.title(\"Count Plot: Source (Industry vs Commodity)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b253a95",
   "metadata": {},
   "source": [
    "### Multivariate Anslysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3c914",
   "metadata": {},
   "source": [
    "##### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=np.number).corr() # Checking correlation between numerical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca48055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Checking data types and non-null counts after mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix \n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db583d9",
   "metadata": {},
   "source": [
    "## Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21013e33-6715-48c5-a642-a33494422a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4490c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17068952-132e-41b7-b0a7-03a181c40611",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[0].min(),X_scaled[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea45023-d977-4ffc-93ca-f1e0e256e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(X_scaled.mean()),np.round(X_scaled.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e863ff",
   "metadata": {},
   "source": [
    "#### Divide the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed53dd6-eb3d-4c51-966b-9cb00133d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42) # Splitting data into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cbc92-59ee-47c0-bd12-f7551b94f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c409f97-8080-43d8-8e67-6be5cafe4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef971a78",
   "metadata": {},
   "source": [
    "### Select the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestRegressor(random_state=42) # Initializing Random Forest Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b47bd",
   "metadata": {},
   "source": [
    "# Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6682a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_train, y_train) # Fitting the model on training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379700a8",
   "metadata": {},
   "source": [
    "# Step 5 Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_y_pred = RF_model.predict(X_test) # Making predictions on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7855332-099e-4de8-8ad7-6b730933929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55610d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_mse = mean_squared_error(y_test, RF_y_pred) # Calculating Mean Squared Error (MSE)\n",
    "RF_rmse = np.sqrt(RF_mse) # Calculating Root Mean Squared Error (RMSE)\n",
    "# Calculating RÂ² score\n",
    "RF_r2 = r2_score(y_test, RF_y_pred)\n",
    "\n",
    "print(f'RMSE: {RF_rmse}')\n",
    "print(f'RÂ² Score: {RF_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d67f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # Importing Linear Regression model \n",
    "LR_model = LinearRegression() # Initializing Linear Regression model\n",
    "# Fitting the Linear Regression model on training data\n",
    "\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "LR_y_pred = LR_model.predict(X_test) # Making predictions on the test set using Linear Regression model \n",
    "\n",
    "\n",
    "LR_mse = mean_squared_error(y_test, LR_y_pred) # Calculating Mean Squared Error (MSE) for Linear Regression model\n",
    "LR_rmse = np.sqrt(LR_mse) # Calculating Root Mean Squared Error (RMSE) for Linear Regression model \n",
    "LR_r2 = r2_score(y_test, LR_y_pred) # Calculating RÂ² score for Linear Regression model \n",
    "\n",
    "print(f'RMSE: {LR_rmse}')\n",
    "print(f'RÂ² Score: {LR_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244584f",
   "metadata": {},
   "source": [
    "# Step 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest Regressor using GridSearchCV \n",
    "# Define the parameter grid for hyperparameter tuning \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters \n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model on the training data \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674cd2a",
   "metadata": {},
   "source": [
    "### Use best parameters for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model to make predictions on the test set \n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "HP_mse = mean_squared_error(y_test, y_pred_best)\n",
    "HP_rmse = np.sqrt(HP_mse)\n",
    "HP_r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f'RMSE: {HP_rmse}')\n",
    "print(f'RÂ² Score: {HP_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386c617",
   "metadata": {},
   "source": [
    "# Step 7: Comapartive Study and Slecting the Best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db49a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparative DataFrame for all models\n",
    "results = {\n",
    "    'Model': ['Random Forest (Default)', 'Linear Regression', 'Random Forest (Tuned)'],\n",
    "    'MSE': [RF_mse, LR_mse, HP_mse],\n",
    "    'RMSE': [RF_rmse, LR_rmse, HP_rmse],\n",
    "    'R2': [RF_r2, LR_r2, HP_r2]\n",
    "}\n",
    "\n",
    "# Create a DataFrame to compare the results of different models\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e3511",
   "metadata": {},
   "source": [
    "If we compare the above three models we can see that linear regression is performing better than random forest regressor. So we will save the linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082db637",
   "metadata": {},
   "source": [
    "### Save model and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d44dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the models if it doesn't exist \n",
    "!mkdir models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and encoders \n",
    "joblib.dump(best_model, 'models/LR_model.pkl')    # Save the best model \n",
    "joblib.dump(scaler, 'models/scaler.pkl') # Save the scaler used for normalization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
